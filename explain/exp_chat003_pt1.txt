
╭─── Claude Code v2.1.37 ──────────────────────────────────────────────────────╮
│                                                 │ Tips for getting started   │
│           Welcome back Tech Shottify!           │ Run /init to create a CLA… │
│                                                 │ ────────────────────────── │
│                     ▐▛███▜▌                     │ Recent activity            │
│                    ▝▜█████▛▘                    │ No recent activity         │
│                      ▘▘ ▝▝                      │                            │
│                                                 │                            │
│              Opus 4.6 · Claude Max              │                            │
│   D:\Personal\Awesome-Wireless-Communications   │                            │
╰──────────────────────────────────────────────────────────────────────────────╯

❯ How is this optimization problem formulated?                              
   The optimization problem (implicitly stated):                            
    max_{W, F}    SE = Σ_{q=1}^{U} Σ_{k=1}^{K} log₂(1 + SINR_{q,k})         
                                                                            
    subject to:                                                             
        |W_{m,n}| = 1/√N_t        (constant modulus for analog precoder)    
        ‖W · F_u[k]‖²_F = 1       (power constraint per user per            
  subcarrier)                                                               
                                                                            
    Why this problem is hard:                                               
    1. The objective function (sum of log₂(1+SINR)) is non-convex in W and  
  F                                                                         
    jointly                                                                 
    2. The constant modulus constraint |W_{m,n}| = 1/√N_t makes the         
  feasible set a                                                            
     manifold, not a convex set                                             
    3. W appears in both numerator and denominator of SINR → fractional     
    programming                                                             
    4. W is shared across all subcarriers but F is per-subcarrier →         
  coupling                                                                  
    between subcarrier problems                                             
    5. The ICI terms create coupling between all subcarriers in the SINR    
    expression                                                              
  Explain me in very details words by words so that I can formulate an      
  optimizatiion problem based on my own problem related to wireless         
  communication.                                                            
  Explain this statement in details:                                        
   The objective function (sum of log₂(1+SINR)) is non-convex in W and F    
    jointly                                                                 
  How the constraints are selected?                                         
  Help me to understand background of the development of such optimization  
  problem.                                                                  
  Do deep research and help me to have a PhD level knowledge in this        
  domain.                                                                   
  Start with explaining in easy terms and then same topic explain in depth  
  using complex term and mathematical expression.                           
  Explain both theoretically and mathematically. For mathematical part,     
  please explain using convensional sign like sum sign, exponential sign    
  etc.  so that it seems I am reading from a text book.                     
  -----------------------                                                   
  If you need to provide a large reponse to fulfill all of my requirements, 
   you can provide your response in chunks.                                 
  Provide first chunk and then after I read this chunk, I will reply next   
  and then you will provided 2nd chunk. In this way!                        

● Let me first look at your existing chat files to understand the specific paper
   and context you're working with.

● Searched for 2 patterns, read 2 files (ctrl+o to expand)

● Now I have full context from your previous sessions. Let me provide a
  comprehensive, textbook-quality explanation. Here is Chunk 1.

  ---
  CHUNK 1: The Art of Formulating Optimization Problems in Wireless 
  Communications

  ---
  Part 1: What is an Optimization Problem? (The Foundation)

  1.1 Everyday Intuition

  Imagine you are a chef cooking dinner for 10 guests. You want to maximize the
  overall taste satisfaction. But you have constraints: limited budget, limited
  cooking time, limited ingredients. You cannot spend infinite money. You cannot
   cook forever. You must work within these limits.

  An optimization problem is exactly this:
  - Objective: What you want to achieve (maximize taste)
  - Decision variables: What you can control (choice of dishes, spices, cooking
  time)
  - Constraints: What limits you (budget, time, ingredients)

  1.2 Formal Mathematical Definition

  An optimization problem has three components:

      maximize (or minimize)    f(x)           ← Objective function
            x

      subject to:               g_i(x) ≤ 0,    i = 1, ..., m     ← Inequality
  constraints
                                h_j(x) = 0,    j = 1, ..., p     ← Equality
  constraints
                                x ∈ X                             ← Domain
  constraint

  Where:
  - x is the decision variable (what we can choose/design)
  - f(x) is the objective function (what we want to optimize)
  - g_i(x) and h_j(x) are constraint functions (what limits our choices)
  - X is the feasible set (the set of all allowed values of x)

  1.3 Why This Matters in Wireless Communications

  In wireless communication, you are the "chef" and:
  - Your guests are the users (mobile phones, IoT devices)
  - Your taste satisfaction is spectral efficiency, throughput, or data rate
  - Your dishes/spices are beamforming matrices, power allocation, subcarrier
  assignment
  - Your budget/time are transmit power limits, hardware constraints, regulatory
   constraints

  ---
  Part 2: How Optimization Problems Are Born in Wireless Communications

  2.1 The General Recipe (Step by Step)

  Every optimization problem in wireless communications is developed through a 
  systematic process. Let me walk you through this process using a general
  framework, and then apply it to your specific paper.

  Step 1: Define the System Model

  Before writing any optimization, you must first describe:
  - What is the transmitter? (BS with N_t antennas, hybrid architecture)
  - What is the receiver? (U single-antenna users)
  - What is the channel? (THz channel with clusters and rays)
  - What is the signal model? (OFDM with K subcarriers)

  This gives you the received signal equation:

      y_q[k] = H_q[k] · (precoder) · s_q[k]  +  interference  +  noise

  Step 2: Define a Performance Metric

  You must decide: what does "good" mean? Common metrics in wireless:
  Metric: Spectral Efficiency (SE)
  Formula: log₂(1 + SINR) bits/s/Hz
  When Used: Most common, capacity-based
  ────────────────────────────────────────
  Metric: Bit Error Rate (BER)
  Formula: P(error)
  When Used: Reliability-focused
  ────────────────────────────────────────
  Metric: Energy Efficiency
  Formula: SE / Power
  When Used: Green communications
  ────────────────────────────────────────
  Metric: Outage Probability
  Formula: P(SINR < threshold)
  When Used: Delay-sensitive systems
  ────────────────────────────────────────
  Metric: Mean Squared Error
  Formula: E[||x - x̂||²]
  When Used: Estimation problems
  The paper chooses Spectral Efficiency because:
  - It directly measures how much data you can transmit per Hz of bandwidth
  - It is the gold standard for capacity-oriented system design
  - Shannon's theorem provides a theoretical ceiling: C = log₂(1 + SNR)

  Step 3: Express the Metric in Terms of Design Variables

  This is where the math gets deep. You take the performance metric and write it
   as a function of the things you can control (beamforming matrices W and F).

  Step 4: Identify Physical and Hardware Constraints

  Ask: what limits exist on the design variables?
  - Physics: total transmit power is finite
  - Hardware: phase shifters can only change phase, not amplitude
  - Regulation: power spectral density limits
  - Architecture: number of RF chains is fixed

  Step 5: Write the Optimization Problem

  Combine steps 2-4 into the formal mathematical form.

  ---
  2.2 The Historical Development

  To have PhD-level understanding, you must know where this problem came from.
  Let me trace the evolution:

  Era 1: Single-User, Single-Antenna (1940s-1990s)

  Shannon (1948) established:
      C = B · log₂(1 + P/(N₀B))     bits/s
  No optimization needed — just one link, one power level. The "optimization"
  was power allocation across frequency (water-filling).

  Era 2: Single-User MIMO (1990s-2000s)

  Telatar (1999) and Foschini (1998) showed MIMO channels have capacity:
      C = Σᵢ log₂(1 + λᵢ Pᵢ / σ²)
  where λᵢ are eigenvalues of HH^H. The optimization is over power allocation
  {Pᵢ} across spatial streams. This is convex (water-filling solution exists).

  Era 3: Multi-User MIMO (2000s-2010s)

  When multiple users share the same channel, the problem becomes:
      max    Σ_q log₂(1 + SINR_q)
      s.t.   Σ_q ||f_q||² ≤ P
  Now SINR_q depends on all users' precoders (one user's signal is another's
  interference). This is non-convex because each user's rate depends on all
  other users' beamformers.

  Key solutions developed:
  - Zero-Forcing (ZF): eliminates inter-user interference, closed-form
  - MMSE: balances interference suppression and noise enhancement
  - Dirty Paper Coding (DPC): capacity-achieving but impractical

  Era 4: Hybrid Beamforming (2014-present)

  When El Ayach et al. (2014) introduced hybrid precoding for mmWave:
      max    Σ_q log₂(1 + SINR_q)
      s.t.   |W_{m,n}| = 1/√N_t        ← NEW: constant modulus
             total power constraint
  The constant modulus constraint made the problem dramatically harder. The
  feasible set is no longer convex — it is a manifold.

  Era 5: ICI-Aware Hybrid Beamforming (This paper, 2020s)

  The paper you are studying adds ICI to the mix:
      max    Σ_q Σ_k log₂(1 + SINR_{q,k})
      s.t.   |W_{m,n}| = 1/√N_t
             ||W · F_u[k]||²_F = 1
  Now SINR_{q,k} contains ICI terms that couple ALL subcarriers together. This
  is the hardest version of the problem.

  ---
  Part 3: The Specific Optimization Problem from the Paper

  3.1 Writing It Out Fully

  Let me now write the complete optimization problem with every detail exposed:

  Decision variables:
  - W ∈ C^(N_t × N_RF) : the analog precoding matrix
  - F_u[k] ∈ C^(N_RF × 1) for all u ∈ {1,...,U}, k ∈ {1,...,K} : the digital 
  precoding vectors

  Objective function:

                    U     K
      max      SE = Σ     Σ   log₂(1 + SINR_{q,k})
      W, F         q=1   k=1

  where:

                          |S₀|² · |H_q[k] · W · F_q[k]|²
      SINR_{q,k} = ──────────────────────────────────────────────
                    I_{q,k}  +  ψ

  and the interference I_{q,k} is:

                U                K
      I_{q,k} = Σ      Σ    |S_{i-k}|² · |H_q[i] · W · F_u[i]|²
               u=1    i=0
               u≠q

                      K
                +     Σ      |S_{i-k}|² · |H_q[i] · W · F_q[i]|²
                     i=0
                     i≠k

  and ψ = Kσ²_n / P (normalized noise power).

  Constraints:

      Constraint 1:   |W_{m,n}| = 1/√N_t      for all m, n

      Constraint 2:   ||W · F_u[k]||²_F = 1    for all u, k

  ---
  3.2 Anatomy of Each Component

  Let me now explain every piece as if you were reading a textbook.

  The Decision Variables: What Can We Control?

  W (Analog Precoder):
  Think of W as a set of "direction knobs." Each element W_{m,n} connects RF
  chain n to antenna m through a phase shifter. You can turn the phase of each 
  connection, but you cannot turn the volume (amplitude is fixed). This is like
  having a steering wheel but no accelerator — you can aim the signal, but
  cannot control its power at the analog stage.

  Mathematically:
      W_{m,n} = (1/√N_t) · e^(j·φ_{m,n})
  You are choosing the phases φ_{m,n} ∈ [0, 2π) for all m ∈ {1,...,N_t} and n ∈
  {1,...,N_RF}. That is N_t × N_RF real-valued parameters to optimize.

  F_u[k] (Digital Precoder):
  Think of F as a "mixing console." For each subcarrier k and each user u, it
  assigns complex weights to the RF chain outputs. Unlike W, the digital
  precoder has no restriction on amplitude or phase — it can do anything.

  There are K × U vectors, each of dimension N_RF. That is K × U × N_RF complex
  parameters, or 2 × K × U × N_RF real parameters.

  The Objective: Why Sum of log₂(1 + SINR)?

  Information-theoretic justification:

  Shannon's fundamental theorem states that for a channel with
  signal-to-interference-plus-noise ratio SINR, the maximum achievable rate (in
  bits per channel use) is:

      R = log₂(1 + SINR)

  This is not an approximation — it is the exact capacity of a Gaussian channel.
   Every wireless engineer's goal is to approach this limit.

  Why the double sum?

  The system has U users and K subcarriers. Each (user, subcarrier) pair is
  essentially an independent "sub-channel" with its own SINR. The total system
  throughput is the sum over all sub-channels:

            U     K
      SE =  Σ     Σ   log₂(1 + SINR_{q,k})
           q=1   k=1

  This is measured in bits/s/Hz and represents the total information the system
  can deliver per second per Hz of bandwidth.

  Why maximize SE?
  - Higher SE means more data delivered to users
  - Directly translates to higher throughput
  - Is the primary design objective in modern cellular standards (4G, 5G, 6G)

  ---
  Part 4: Why the Objective Function Is Non-Convex (The Deep Explanation)

  This is the core of your question. I will explain this at three levels:
  intuitive, intermediate, and rigorous.

  4.1 Level 1: Intuitive Understanding

  What does "convex" mean in simple terms?

  A function f(x) is convex if, when you draw a straight line between any two 
  points on its graph, the line always stays above the graph. Think of a bowl —
  any line connecting two points on the rim stays above the inside of the bowl.

  A function is non-convex if you can find two points where the straight line
  dips below the graph. Think of a mountain landscape with multiple valleys —
  lines between mountain peaks can dip below hilltops.

  Why does convexity matter?

  - Convex problem: Any local minimum is also the global minimum. Gradient
  descent always finds the best solution. Easy to solve.
  - Non-convex problem: There can be many local minima. Gradient descent might
  get stuck in a bad valley. Hard to solve — you might find a good solution but 
  never know if it is the best.

  Why is our problem non-convex?

  Imagine you have two "knobs" — W and F. As you turn W, the landscape of the
  objective function changes shape. As you turn F, the landscape changes again.
  The combined landscape of turning both knobs simultaneously has many hills and
   valleys — there is no single "bowl shape."

  4.2 Level 2: Intermediate Understanding

  Let me show you three specific reasons why non-convexity arises:

  Reason 1: The Ratio Structure of SINR

  SINR has the form:

                  Signal(W, F)
      SINR = ──────────────────────
              Interference(W, F) + Noise

  Both Signal and Interference depend on W and F. Consider what happens:
  - If you increase W in a direction that boosts signal for user 1, you might 
  also increase interference to user 2
  - The ratio Signal/Interference is not convex in general, even if Signal and
  Interference individually are simple functions

  A simple example: consider f(x) = x² / (1 + x²). This is a ratio of two convex
   functions, but f(x) itself is not convex (it has an inflection point and
  levels off at 1).

  Reason 2: The log₂ of a Non-Convex Function

  Even if SINR were convex (it is not), log₂(1 + SINR) would be:
  - log₂(1 + x) is concave in x (curves downward)
  - A concave function of a convex function is not necessarily convex or concave
  - The composition breaks convexity

  But the deeper issue is that SINR itself is already non-convex, so log₂(1 +
  SINR) inherits and amplifies the non-convexity.

  Reason 3: The Coupling Between W and F

  The signal power is:
      |H_q[k] · W · F_q[k]|²

  This is a function of the product W · F. Even if we think of the effective
  precoder as a single variable V = W · F, the constraint |W_{m,n}| = 1/√N_t
  prevents us from treating it this way. The factorization W · F with
  constrained W creates non-convexity.

  Think of it like this: if I tell you that x · y = 12 and |x| = 2, there are 
  multiple solutions (x=2,y=6 or x=-2,y=-6 or x=2j,y=-6j...). The
  "multiplication coupling" between constrained variables creates a non-convex
  feasible set.

  4.3 Level 3: Rigorous Mathematical Proof

  Now let me prove non-convexity formally. A function f(x) is convex if and only
   if:

      f(λx₁ + (1-λ)x₂) ≤ λf(x₁) + (1-λ)f(x₂)     for all λ ∈ [0,1]

  Equivalently, the Hessian matrix ∇²f must be positive semidefinite everywhere.

  Proof via the SINR structure:

  Consider a simplified single-user, single-subcarrier case to isolate the
  non-convexity. Let w be the analog beamforming vector and f be the digital
  beamforming vector. The SINR simplifies to:

                  |h^H w f|²
      SINR = ─────────────────
                    σ²

  and the rate is R = log₂(1 + |h^H w f|² / σ²).

  Now consider the variable v = w f (a scalar times a vector, or more generally 
  a matrix product). The function |h^H v|² is convex in v (it is a squared
  linear function). And log₂(1 + |h^H v|²/σ²) is concave in v (concave function
  of a convex function, by composition rules for concave-of-affine).

  So for a single variable v, maximizing R is a concave maximization — which is
  easy!

  But we do not optimize over v. We optimize over (w, f) separately with the
  constraint |w_m| = 1/√N_t. Let us see what happens:

  Let w = [e^(jθ₁), e^(jθ₂)]^T / √2 (for N_t = 2) and f = β (a scalar).

  Then:
      v = w · f = β/√2 · [e^(jθ₁), e^(jθ₂)]^T

  The rate becomes:
      R(θ₁, θ₂, β) = log₂(1 + |β|²/2 · |h₁ e^(jθ₁) + h₂ e^(jθ₂)|² / σ²)

  Now compute the Hessian with respect to (θ₁, θ₂, β):

  The term |h₁ e^(jθ₁) + h₂ e^(jθ₂)|² expands as:
      = |h₁|² + |h₂|² + 2Re(h₁ h₂* e^(j(θ₁-θ₂)))

  This contains cos(θ₁ - θ₂) terms. The second derivative of cos(θ₁ - θ₂) with
  respect to θ₁ is -cos(θ₁ - θ₂), which can be positive or negative. Therefore:

      ∂²R/∂θ₁² can be > 0 or < 0 depending on (θ₁, θ₂)

  This means the Hessian is indefinite — it is neither positive semidefinite nor
   negative semidefinite. Therefore R is neither convex nor concave in (θ₁, θ₂,
  β).

  QED: The objective function is non-convex in (W, F) jointly.

  The multi-user case makes it even worse:

  With multiple users, each user's SINR has the form:

                          |H_q W F_q|²
      SINR_q = ──────────────────────────────────
                Σ_{u≠q} |H_q W F_u|²  +  σ²

  Now W appears in both numerator and denominator. Changing W to improve user
  1's signal simultaneously changes user 2's interference. This creates a
  game-theoretic coupling that generates additional non-convexity.

  The ICI terms add yet another layer: subcarrier k's SINR depends on the 
  beamforming on ALL other subcarriers through the S_{i-k} coefficients,
  creating K-fold coupling.

  ---
  Part 5: Summary of Chunk 1
  Topic: Optimization structure
  Key Takeaway: objective + decision variables + constraints
  ────────────────────────────────────────
  Topic: Historical evolution
  Key Takeaway: single-antenna → MIMO → MU-MIMO → hybrid → ICI-aware hybrid
  ────────────────────────────────────────
  Topic: Decision variables
  Key Takeaway: W (phases only) and F (unrestricted complex)
  ────────────────────────────────────────
  Topic: Objective
  Key Takeaway: Sum-rate SE = ΣΣ log₂(1+SINR) — the Shannon capacity metric
  ────────────────────────────────────────
  Topic: Non-convexity source 1
  Key Takeaway: SINR is a ratio where W,F appear in both numerator and
    denominator
  ────────────────────────────────────────
  Topic: Non-convexity source 2
  Key Takeaway: log₂ composed with a non-convex function remains non-convex
  ────────────────────────────────────────
  Topic: Non-convexity source 3
  Key Takeaway: The product coupling W·F with constrained W creates indefinite
    Hessian
  ────────────────────────────────────────
  Topic: Consequence
  Key Takeaway: No guaranteed global optimum; must use iterative/alternating
    methods
  ---
  In Chunk 2, I will cover:
  1. How constraints are selected — the physics and hardware behind each
  constraint, why those specific constraints and not others, and how to choose
  constraints for your own problem
  2. The complete background of constraint design philosophy in wireless
  optimization
  3. A step-by-step guide for formulating your own optimization problem

  Reply "next" when you are ready for Chunk 2.

✻ Brewed for 2m 9s

❯ next 

● CHUNK 2: How Constraints Are Selected & The Philosophy of Constraint Design

  ---
  Part 6: What Are Constraints and Why Do They Exist?

  6.1 Intuitive Understanding

  Without constraints, every optimization problem would have a trivial solution:
   make everything infinite.

  Want to maximize data rate? Use infinite power. Want to serve all users
  perfectly? Use infinite antennas with infinite RF chains. Want zero
  interference? Use infinite bandwidth so every user gets their own frequency.

  Obviously, the real world does not allow this. Constraints represent the
  boundary between imagination and reality. They encode three categories of
  limitations:

      ┌─────────────────────────────────────────────────────┐
      │              SOURCES OF CONSTRAINTS                  │
      ├─────────────────────────────────────────────────────┤
      │  1. PHYSICS       → Laws of nature you cannot break │
      │  2. HARDWARE      → What your equipment can do      │
      │  3. REGULATION    → Rules imposed by authorities    │
      └─────────────────────────────────────────────────────┘

  6.2 The Two Constraints in This Paper

  The paper has exactly two constraints. Let me explain each one from first
  principles.

  ---
  Part 7: Constraint 1 — The Constant Modulus Constraint

      |W_{m,n}| = 1/√N_t      for all m = 1,...,N_t  and  n = 1,...,N_RF

  7.1 Easy Explanation: The Phase Shifter Story

  Imagine you have a flashlight (an antenna). You can rotate the flashlight to
  point in any direction, but you cannot make it brighter or dimmer — the
  brightness is fixed.

  In analog beamforming, each connection between an RF chain and an antenna goes
   through a phase shifter. A phase shifter is an electronic component that 
  delays the signal by a controllable amount. This delay changes the phase of
  the signal but not its amplitude.

  Why? Because a phase shifter is essentially a variable-length transmission
  line:
  - Longer path = more delay = more phase shift
  - But the signal power remains the same (ignoring small insertion losses)

  So each element W_{m,n} of the analog precoding matrix can be written as:

      W_{m,n} = A · e^(j·φ_{m,n})

  where:
  - A is the fixed amplitude (you cannot change it)
  - φ_{m,n} is the controllable phase (you can change it from 0 to 2π)
  - j = √(-1) is the imaginary unit

  The value A = 1/√N_t is chosen for power normalization (explained below).

  7.2 Why Exactly 1/√N_t? (The Power Normalization)

  Consider the analog precoder W applied to a signal vector x from the RF 
  chains:

      transmitted signal = W · x     ∈ ℂ^(N_t × 1)

  The total transmitted power is:

      P_tx = ||W · x||² = x^H · W^H · W · x

  For this to be properly normalized, we want W^H · W to behave like an identity
   matrix (up to scaling). If each element of W has magnitude A, then:

      [W^H · W]_{n,n} = Σ_{m=1}^{N_t} |W_{m,n}|² = N_t · A²

  Setting A = 1/√N_t gives:

      [W^H · W]_{n,n} = N_t · (1/√N_t)² = N_t · 1/N_t = 1

  This ensures that the analog precoder does not amplify or attenuate the total
  power — it only redirects it spatially. The total transmit power is controlled
   entirely by the digital precoder and the power amplifier.

  7.3 The Geometric Meaning: Life on a Circle

  Each element W_{m,n} = (1/√N_t) · e^(j·φ) lives on a circle in the complex
  plane:

      Imaginary axis
           ↑
           |      · (W_{m,n} for some φ)
           |    /
           |  /  radius = 1/√N_t
           |/
      ─────●──────────→ Real axis
           |
           |

  All possible values of W_{m,n} trace out a circle of radius 1/√N_t centered at
   the origin. You can be anywhere on this circle, but you cannot leave it.

  The entire matrix W lives on a product of circles:

      M = S¹(1/√N_t) × S¹(1/√N_t) × ... × S¹(1/√N_t)
          \_____________________________________________/
                        N_t × N_RF  copies

  This is a torus (donut shape in high dimensions). It is a smooth manifold — a
  curved surface embedded in higher-dimensional space.

  7.4 Why This Constraint Makes the Problem Hard

  In a convex optimization problem, the feasible set (the set of all allowed
  solutions) must be convex. A set is convex if, for any two points in the set, 
  the straight line between them also lies in the set.

  Test: Take two points on the circle, say W₁ = (1/√N_t) · e^(j·0) and W₂ =
  (1/√N_t) · e^(j·π). The midpoint is:

      W_mid = (W₁ + W₂)/2 = (1/√N_t)(1 + (-1))/2 = 0

  But |W_mid| = 0 ≠ 1/√N_t. The midpoint violates the constant modulus
  constraint! Therefore the circle is not a convex set.

  A more visual proof:

      Imaginary axis
           ↑
           |
        W₂ ·─────────── midpoint = 0 ──────────· W₁
           |            (NOT on circle!)
           |
      ─────●──────────→ Real axis
           |

  The straight line between W₁ and W₂ passes through zero, which is not on the
  circle. The feasible set is non-convex.

  Consequence: Standard convex optimization algorithms (interior point methods,
  projected gradient descent onto convex sets) cannot be directly applied. You
  need specialized algorithms that respect the manifold geometry — hence the
  Riemannian manifold optimization in the paper.

  7.5 Alternative Constraint: What If We Used Variable Gain Phase Shifters?

  Some papers consider variable-gain phase shifters where:

      |W_{m,n}| ≤ 1/√N_t      (inequality instead of equality)

  This makes the feasible set a disk (filled circle) instead of a circle 
  boundary. A disk IS convex! But:
  - Variable-gain phase shifters are more expensive
  - They require additional amplitude control circuitry
  - The paper assumes constant-modulus phase shifters (the most common and
  cheapest)

  This illustrates a key lesson: the choice of constraint depends on the
  hardware you assume.

  ---
  Part 8: Constraint 2 — The Power Normalization Constraint

      ||W · F_u[k]||²_F = 1      for all u = 1,...,U  and  k = 1,...,K

  8.1 Easy Explanation: The Total Volume Control

  Imagine a sound system with multiple speakers. Each speaker has its own volume
   knob (the digital precoder F), and all speakers pass through a shared
  equalizer (the analog precoder W). The combined output W · F determines how 
  loud each speaker actually is.

  The constraint says: the total output power for each user on each subcarrier
  must equal exactly 1 (normalized unit). This prevents the system from
  "cheating" by simply increasing the transmission power.

  8.2 Why This Specific Form?

  The combined precoder for user u on subcarrier k is:

      v_u[k] = W · F_u[k]     ∈ ℂ^(N_t × 1)

  This is the actual beamforming vector applied at the N_t antennas. Its squared
   Frobenius norm is:

      ||v_u[k]||²_F = ||W · F_u[k]||²_F = Σ_{m=1}^{N_t} |v_m|²

  This equals the total power radiated by all antennas for user u on subcarrier
  k. Setting this to 1 means:

      Per-user, per-subcarrier transmit power = 1 (normalized)

  The actual physical power is then P/(K·U) per user per subcarrier, which is
  absorbed into the SNR definition (ψ = Kσ²_n/P).

  8.3 The Deeper Reason: Preventing Trivial Solutions

  Without this constraint, the optimizer could trivially increase SE by scaling
  F to infinity:

      SINR_{q,k} = |S₀|² · |H_q[k] · W · (α·F_q[k])|² / (I_{q,k} + ψ)

  As α → ∞, the numerator grows as α², and the interference terms in the
  denominator also grow as α². So the SINR ratio approaches a finite limit — but
   the optimizer might waste time trying large values of F.

  More importantly, in practice, the power amplifier has a maximum output power.
   The normalization constraint ensures we stay within this limit.

  8.4 Why ||W·F||² and Not Just ||F||²?

  This is subtle and important. Some papers use:

      Alternative:  ||F_u[k]||² = 1     (normalize digital precoder only)

  But this paper normalizes the combined precoder W·F. Why?

  Because the actual power at the antennas depends on both W and F:
  - F controls the power entering each RF chain
  - W redistributes this power across antennas
  - The total radiated power is ||W·F||², not ||F||²

  If you only normalize ||F||², the total radiated power would be:

      ||W·F||² = F^H · W^H · W · F

  Since W^H·W is generally NOT the identity matrix (unless columns of W are
  orthonormal), ||W·F||² ≠ ||F||². Normalizing only F would give incorrect power
   control.

  8.5 Equality vs. Inequality Constraint

  The paper uses equality (= 1) rather than inequality (≤ 1). Why?

  Theorem: At the optimum of a rate maximization problem with a power
  constraint, the power constraint is always tight (active). That is, the
  optimal solution always uses all available power.

  Proof sketch: Suppose the optimum occurs at ||W·F_u[k]||² = P₀ < 1. Then we 
  can scale F_u[k] by √(1/P₀) > 1, which increases ||W·F_u[k]||² to 1 and 
  increases the numerator of SINR without changing the structure of the
  denominator relative to the numerator. This would increase SE, contradicting
  the assumption that P₀ was optimal.

  Therefore, we lose nothing by replacing ≤ with =, and the equality constraint
  is easier to handle mathematically.

  ---
  Part 9: The Philosophy of Constraint Selection in Wireless Optimization

  9.1 The General Framework

  When formulating any wireless optimization problem, constraints come from four
   questions:

      ┌────────────────────────────────────────────────────────────────┐
      │  QUESTION 1: What does the physics allow?                      │
      │  → Power constraints (conservation of energy)                  │
      │  → Causality constraints (you cannot use future information)   │
      │  → Bandwidth constraints (Nyquist, Shannon)                    │
      │                                                                │
      │  QUESTION 2: What does the hardware support?                   │
      │  → Constant modulus (phase shifters)                           │
      │  → Finite resolution (quantized phases, finite DAC bits)       │
      │  → Number of RF chains (N_RF < N_t)                           │
      │  → Antenna array geometry (UPA, ULA)                          │
      │                                                                │
      │  QUESTION 3: What does the standard/regulation require?        │
      │  → Maximum transmit power (EIRP limits)                       │
      │  → Power spectral density masks                               │
      │  → Out-of-band emission limits                                │
      │                                                                │
      │  QUESTION 4: What does the system design impose?               │
      │  → QoS requirements (minimum rate per user)                    │
      │  → Fairness constraints (max-min fairness)                    │
      │  → Latency constraints                                        │
      │  → Backhaul capacity constraints                              │
      └────────────────────────────────────────────────────────────────┘

  9.2 Catalog of Common Constraints in Wireless Optimization

  Let me give you a comprehensive reference table that will help you formulate
  your own problems:

  Category A: Power Constraints
  ┌─────────────────────┬─────────────────────┬────────────────────────────────┐
  │     Constraint      │  Mathematical Form  │        Physical Meaning        │
  ├─────────────────────┼─────────────────────┼────────────────────────────────┤
  │ Total power         │ Σ_u ||f_u||² ≤ P    │ Total BS transmit power is     │
  │                     │                     │ limited                        │
  ├─────────────────────┼─────────────────────┼────────────────────────────────┤
  │ Per-antenna power   │ |[WF]_m|² ≤ P_m     │ Each antenna/PA has its own    │
  │                     │                     │ limit                          │
  ├─────────────────────┼─────────────────────┼────────────────────────────────┤
  │ Per-user power      │ ||W·F_u||² ≤ P_u    │ Each user gets a power budget  │
  ├─────────────────────┼─────────────────────┼────────────────────────────────┤
  │ Per-subcarrier      │ Σ_u ||F_u[k]||² ≤   │ Spectral mask constraint       │
  │ power               │ P_k                 │                                │
  ├─────────────────────┼─────────────────────┼────────────────────────────────┤
  │ Combined normalized │ ||W·F_u[k]||² = 1   │ This paper's constraint        │
  └─────────────────────┴─────────────────────┴────────────────────────────────┘
  Category B: Hardware Constraints
  Constraint: Constant modulus
  Mathematical Form: |W_{m,n}| = 1/√N_t
  Physical Meaning: This paper: phase-only control
  ────────────────────────────────────────
  Constraint: Finite phase resolution
  Mathematical Form: φ ∈ {0, 2π/2^b, ..., 2π(2^b-1)/2^b}
  Physical Meaning: b-bit phase shifters
  ────────────────────────────────────────
  Constraint: Block diagonal W
  Mathematical Form: W = blkdiag(W₁,...,W_{N_RF})
  Physical Meaning: Partially connected architecture
  ────────────────────────────────────────
  Constraint: Rank constraint
  Mathematical Form: rank(F[k]) ≤ N_s
  Physical Meaning: Limited number of data streams
  Category C: QoS Constraints
  Constraint: Minimum rate
  Mathematical Form: log₂(1+SINR_q) ≥ R_min
  Physical Meaning: Each user needs minimum throughput
  ────────────────────────────────────────
  Constraint: Maximum BER
  Mathematical Form: BER_q ≤ 10^(-target)
  Physical Meaning: Reliability requirement
  ────────────────────────────────────────
  Constraint: Maximum outage
  Mathematical Form: P(SINR_q < γ) ≤ ε
  Physical Meaning: Probabilistic guarantee
  Category D: Fairness Constraints
  ┌──────────────────────┬──────────────────────────┬──────────────────────────┐
  │      Constraint      │    Mathematical Form     │     Physical Meaning     │
  ├──────────────────────┼──────────────────────────┼──────────────────────────┤
  │ Max-min fairness     │ Objective: max min_q R_q │ Worst user is maximized  │
  ├──────────────────────┼──────────────────────────┼──────────────────────────┤
  │ Proportional         │ Objective: max Σ         │ Logarithmic utility      │
  │ fairness             │ log(R_q)                 │                          │
  ├──────────────────────┼──────────────────────────┼──────────────────────────┤
  │ Rate ratios          │ R_q / R_u ≥ α_{q,u}      │ Priority-based           │
  │                      │                          │ allocation               │
  └──────────────────────┴──────────────────────────┴──────────────────────────┘
  9.3 Why This Paper Uses Only Two Constraints (And Not More)

  The paper chooses a minimal constraint set. This is deliberate:

  1. Constraint 1 (constant modulus) is unavoidable — it is a hardware fact. If
  you use phase shifters, this constraint exists whether you write it or not.
  2. Constraint 2 (power normalization) is necessary for a well-posed problem. 
  Without it, the problem is unbounded (SE → ∞ as power → ∞).
  3. No QoS constraints — The paper aims for sum-rate maximization, not per-user
   guarantees. This is simpler and shows the fundamental performance limits. A
  follow-up paper might add minimum rate constraints.
  4. No finite phase resolution — The paper assumes continuous phase shifters
  (infinite resolution). This is an idealization. Practical systems use 4-8 bit
  phase shifters. Including quantization would add combinatorial (discrete)
  constraints, making the problem much harder.
  5. No per-antenna power constraints — The paper uses total power
  normalization, not per-antenna. Per-antenna constraints would be needed for
  distributed antenna systems or when individual power amplifiers have different
   limits.

  Key insight for your own work: Start with the minimum necessary constraints.
  Add more only when they represent real physical limitations in your specific
  system.

  ---
  Part 10: Step-by-Step Guide to Formulating Your Own Optimization Problem

  Let me give you a concrete recipe that you can follow for any wireless
  communication problem.

  Step 1: Draw the System Diagram

      [Data source] → [Encoder] → [Precoder/Beamformer] → [Channel] → [Receiver]
   → [Decoder]

  Identify:
  - How many transmitters? How many receivers?
  - How many antennas at each?
  - What is the channel model?
  - What signal processing is performed?

  Step 2: Write the Received Signal Equation

  This is always the starting point. For a general MIMO system:

      y = H · x + n

  where x = (precoding) · (data symbols). Be specific about:
  - Dimensions of each matrix/vector
  - What is deterministic vs. random
  - What interference terms exist

  Step 3: Compute SINR (or Your Chosen Metric)

  From the received signal, derive:

                      Desired signal power
      SINR = ─────────────────────────────────────
              Interference power + Noise power

  Express this entirely in terms of your design variables and known quantities
  (channel, noise power).

  Step 4: Choose Your Objective Function

  Ask yourself: What do I want to optimize?

      ┌─────────────────────────────────────────────────────────┐
      │  "I want maximum total throughput"                       │
      │  → max Σ log₂(1 + SINR_q)         (sum-rate)           │
      │                                                         │
      │  "I want the worst user to be as good as possible"      │
      │  → max  min_q  log₂(1 + SINR_q)   (max-min fairness)  │
      │                                                         │
      │  "I want minimum power to achieve target rates"         │
      │  → min  P   s.t. SINR_q ≥ γ_q     (power minimization)│
      │                                                         │
      │  "I want maximum energy efficiency"                     │
      │  → max  Σ log₂(1+SINR_q) / P_total (EE maximization)  │
      │                                                         │
      │  "I want minimum error"                                 │
      │  → min  E[||s - ŝ||²]              (MSE minimization)  │
      └─────────────────────────────────────────────────────────┘

  Step 5: List All Constraints

  Go through each category systematically:

      □ Power constraints:     What power limits exist?
      □ Hardware constraints:  What can your hardware actually do?
      □ QoS constraints:       What minimum performance is required?
      □ Fairness constraints:  How should resources be distributed?
      □ Regulatory:            What does the standard/regulation require?
      □ Information:           What does each node know? (CSI availability)

  Step 6: Write the Complete Problem

  Assemble everything into the standard form:

      maximize (or minimize)    f(W, F, P, ...)

      subject to:
          constraint_1(W, F, P, ...) ≤ 0    or    = 0
          constraint_2(W, F, P, ...) ≤ 0    or    = 0
          ...
          constraint_m(W, F, P, ...) ≤ 0    or    = 0

  Step 7: Analyze the Problem Structure

  Ask:
  - Is the objective convex or non-convex?
  - Are the constraints convex?
  - What type of problem is this? (LP, QP, QCQP, SDP, non-convex?)
  - Can it be decomposed? (separate variables, per-subcarrier, per-user)
  - Are there known solution methods in the literature?

  Step 8: Choose a Solution Approach

      ┌──────────────────────┬─────────────────────────────────────┐
      │  Problem Type        │  Solution Method                    │
      ├──────────────────────┼─────────────────────────────────────┤
      │  Convex              │  CVX, interior point, gradient      │
      │  Non-convex, smooth  │  Alternating optimization, SCA,     │
      │                      │  manifold optimization, MM          │
      │  Non-convex, discrete│  Branch-and-bound, relaxation       │
      │  Large-scale         │  ADMM, distributed algorithms       │
      │  Unknown structure   │  Deep learning, reinforcement       │
      │                      │  learning                           │
      └──────────────────────┴─────────────────────────────────────┘

  ---
  Part 11: Applying This Framework — A Worked Example

  Let me show you how the paper's problem follows this exact recipe.

  Step 1 (System): BS with N_t antennas, N_RF RF chains, U single-antenna users,
   K OFDM subcarriers, THz channel with ICI.

  Step 2 (Received signal):
      y_q[k] = S₀ · H_q[k] · W · F_q[k] · s_q[k]  +  Δ_{q,k}  +  n[k]

  Step 3 (SINR):
      SINR_{q,k} = |S₀|² · |H_q[k] · W · F_q[k]|² / (I_{q,k} + ψ)

  Step 4 (Objective): Sum-rate maximization:
      max  SE = Σ_{q=1}^{U}  Σ_{k=1}^{K}  log₂(1 + SINR_{q,k})

  Step 5 (Constraints):
      □ Hardware:  |W_{m,n}| = 1/√N_t   (phase shifters)       ✓
      □ Power:     ||W·F_u[k]||² = 1     (power normalization)  ✓
      □ QoS:       none (sum-rate, not per-user)                 -
      □ Fairness:  none (not considered)                         -

  Step 6 (Complete problem):
      max_{W, F}    Σ_{q=1}^{U}  Σ_{k=1}^{K}  log₂(1 + SINR_{q,k})

      s.t.    |W_{m,n}| = 1/√N_t        ∀ m, n
              ||W · F_u[k]||²_F = 1      ∀ u, k

  Step 7 (Analysis): Non-convex objective (proven in Chunk 1), non-convex 
  constraint (constant modulus). This is a non-convex optimization problem on a
  Riemannian manifold.

  Step 8 (Solution): Alternating optimization (fix W, solve F by ZF; fix F, 
  solve W by Riemannian conjugate gradient). This is exactly what the paper
  does.

  ---
  Part 12: How to Modify This for Your Own Problem

  Here are concrete examples of how you might create variants:

  Variant 1: Add minimum rate constraints
      max_{W, F}    Σ Σ log₂(1 + SINR_{q,k})
      s.t.          |W_{m,n}| = 1/√N_t
                    ||W·F_u[k]||² = 1
                    Σ_k log₂(1 + SINR_{q,k}) ≥ R_min,q    ← NEW: per-user QoS
  This ensures every user gets at least R_min,q bits/s/Hz.

  Variant 2: Energy efficiency maximization
      max_{W, F}    [Σ Σ log₂(1 + SINR_{q,k})] / [P_total + P_circuit]
      s.t.          |W_{m,n}| = 1/√N_t
                    ||W·F_u[k]||² ≤ P_max/(K·U)         ← inequality now
  The objective is now a ratio of sum-rate to total power (including circuit 
  power). This is a fractional programming problem — even harder.

  Variant 3: Partially connected architecture
      max_{W, F}    Σ Σ log₂(1 + SINR_{q,k})
      s.t.          |W_{m,n}| = 1/√N_t
                    W = blkdiag(w₁, w₂, ..., w_{N_RF})    ← NEW: block diagonal
                    ||W·F_u[k]||² = 1
  Each RF chain connects to only N_t/N_RF antennas. This reduces hardware 
  complexity but limits beamforming flexibility.

  Variant 4: Robust design under imperfect CSI
      max_{W, F}    min_{ΔH: ||ΔH||≤ε}  Σ Σ log₂(1 + SINR_{q,k}(H + ΔH))
      s.t.          |W_{m,n}| = 1/√N_t
                    ||W·F_u[k]||² = 1
  This is a worst-case robust formulation. The channel H is known imperfectly
  with error bound ε. The design must work for the worst possible channel within
   the uncertainty set.

  ---
  Summary of Chunk 2
  Topic: Constraint 1 (constant modulus)
  Key Takeaway: Comes from phase shifter hardware; makes feasible set a
    non-convex manifold (torus)
  ────────────────────────────────────────
  Topic: Why 1/√N_t
  Key Takeaway: Power normalization: ensures analog precoder neither amplifies
    nor attenuates
  ────────────────────────────────────────
  Topic: Constraint 2 (power normalization)
  Key Takeaway: Prevents unbounded solutions; the combined precoder W·F must
  have
     unit power
  ────────────────────────────────────────
  Topic: Why equality not inequality
  Key Takeaway: At optimum, power constraint is always tight (using full power
  is
     always better)
  ────────────────────────────────────────
  Topic: Constraint philosophy
  Key Takeaway: Start minimal: only hardware facts + well-posedness; add
    QoS/fairness if needed
  ────────────────────────────────────────
  Topic: Your own problem
  Key Takeaway: Follow the 8-step recipe: system → signal → SINR → objective →
    constraints → formulate → analyze → solve
  ---
  In Chunk 3, I will cover:
  1. Convexity theory in depth — formal definitions, how to test convexity, the
  role of the Hessian, convex relaxation techniques
  2. Solution methods for non-convex wireless problems — alternating
  optimization, successive convex approximation (SCA), semidefinite relaxation
  (SDR), manifold optimization
  3. Why the paper reformulates to interference minimization — the mathematical
  justification with full derivation
  4. Connection to modern research directions — deep learning-based beamforming,
   RIS-assisted systems, and how optimization problems evolve

  Reply "next" when you are ready for Chunk 3.

✻ Churned for 2m 19s

❯ next 

● CHUNK 3: Convexity Theory, Solution Methods, and the Reformulation Strategy

  ---
  Part 13: Convexity Theory — The Mathematical Foundation

  13.1 Why You Must Understand Convexity

  In optimization, there is a sharp divide:

      ┌──────────────────────────────────────────────────────────┐
      │                                                          │
      │   CONVEX problems → Solved EFFICIENTLY and GLOBALLY      │
      │                     (polynomial time, guaranteed optimum) │
      │                                                          │
      │   NON-CONVEX problems → Generally NP-hard                │
      │                         (no guaranteed global optimum)    │
      │                                                          │
      └──────────────────────────────────────────────────────────┘

  Every PhD student in wireless communications must understand this divide
  because it determines:
  - Whether your problem has a tractable solution
  - Which algorithms you can use
  - Whether you need to reformulate or approximate
  - What performance guarantees you can claim

  13.2 Formal Definitions

  Definition 1: Convex Set

  A set C ⊆ ℝⁿ is convex if for any two points x₁, x₂ ∈ C and any λ ∈ [0, 1]:

      λ·x₁ + (1-λ)·x₂  ∈  C

  In words: the line segment between any two points in C lies entirely within C.

  Examples:
      Convex sets:                    Non-convex sets:

      ┌─────────┐                     ┌──────┐
      │         │  (rectangle)        │      └──┐  (L-shape)
      │         │                     │         │
      └─────────┘                     └─────────┘

         ╭───╮                           ╭╮  ╭╮
        │     │   (circle/disk)         │  ╰╯  │  (figure-8)
         ╰───╯                           ╰────╯

      The unit circle boundary S¹ = {x : |x| = 1} is NOT convex
      (midpoint of two opposite points = 0, which is not on S¹)

  The constant modulus constraint set {W : |W_{m,n}| = 1/√N_t} is a product of
  circles, hence NOT convex. This is why our problem is fundamentally hard.

  Definition 2: Convex Function

  A function f: ℝⁿ → ℝ is convex if for any x₁, x₂ ∈ dom(f) and any λ ∈ [0, 1]:

      f(λ·x₁ + (1-λ)·x₂)  ≤  λ·f(x₁) + (1-λ)·f(x₂)

  In words: the function value at any point on the line segment is at most the
  linearly interpolated value. The function "curves upward" (like a bowl).

  Definition 3: Concave Function

  f is concave if -f is convex. Equivalently:

      f(λ·x₁ + (1-λ)·x₂)  ≥  λ·f(x₁) + (1-λ)·f(x₂)

  The function "curves downward" (like a hill). Maximizing a concave function is
   equivalent to minimizing a convex function — both are "easy."

  Definition 4: Convex Optimization Problem

  A problem is convex if:
  - The objective is convex (for minimization) or concave (for maximization)
  - All inequality constraints g_i(x) ≤ 0 have convex g_i
  - All equality constraints h_j(x) = 0 have affine h_j (i.e., h_j(x) = aᵀx + b)

  13.3 The Hessian Test for Convexity

  For a twice-differentiable function f(x), convexity can be checked via the
  Hessian matrix:

                    ┌                                          ┐
                    │  ∂²f/∂x₁²      ∂²f/∂x₁∂x₂  ...        │
      H(x) = ∇²f = │  ∂²f/∂x₂∂x₁    ∂²f/∂x₂²    ...        │
                    │  ...            ...           ...        │
                    └                                          ┘

  Theorem: f is convex if and only if H(x) is positive semidefinite (PSD) for
  all x in the domain. That is:

      zᵀ · H(x) · z  ≥  0      for all z ∈ ℝⁿ, for all x

  This means all eigenvalues of H(x) are non-negative everywhere.

  f is concave if and only if H(x) is negative semidefinite (NSD) everywhere.

  f is neither convex nor concave if H(x) is indefinite at some point (has both
  positive and negative eigenvalues).

  13.4 Applying the Hessian Test to Our Problem

  Let me demonstrate with the simplified single-user SINR. Consider:

      R(θ) = log₂(1 + |h₁e^(jθ₁) + h₂e^(jθ₂)|² / σ²)

  where θ = [θ₁, θ₂]ᵀ are the phase shifter angles for a 2-antenna system.

  Step 1: Let g(θ) = |h₁e^(jθ₁) + h₂e^(jθ₂)|²

  Expanding:
      g(θ) = |h₁|² + |h₂|² + 2|h₁||h₂|cos(θ₁ - θ₂ + ∠h₁ - ∠h₂)

  Let φ₀ = ∠h₁ - ∠h₂ (a constant). Then:

      g(θ) = |h₁|² + |h₂|² + 2|h₁||h₂|cos(θ₁ - θ₂ + φ₀)

  Step 2: Compute the Hessian of g(θ):

      ∂g/∂θ₁ = -2|h₁||h₂|sin(θ₁ - θ₂ + φ₀)

      ∂²g/∂θ₁² = -2|h₁||h₂|cos(θ₁ - θ₂ + φ₀)

      ∂²g/∂θ₁∂θ₂ = +2|h₁||h₂|cos(θ₁ - θ₂ + φ₀)

  The Hessian of g is:

                ┌                    ┐
      H_g = c · │  -1      +1       │      where c = 2|h₁||h₂|cos(θ₁-θ₂+φ₀)
                │  +1      -1       │
                └                    ┘

  Step 3: Check eigenvalues of H_g:

  The matrix [-1, +1; +1, -1] has eigenvalues 0 and -2.

  So H_g has eigenvalues 0 and -2c.

  When cos(θ₁-θ₂+φ₀) > 0: eigenvalues are 0 and -2c < 0 → H_g is NSD → g is
  locally concave

  When cos(θ₁-θ₂+φ₀) < 0: eigenvalues are 0 and -2c > 0 → H_g is PSD → g is
  locally convex

  The Hessian changes sign depending on θ! Therefore g(θ) is neither globally
  convex nor globally concave.

  Step 4: Since R = log₂(1 + g/σ²) is a concave increasing function composed
  with g, and g is neither convex nor concave, R inherits this indefiniteness. 
  R(θ) is non-convex in θ.

  This is the rigorous proof for even the simplest case. With multiple users,
  subcarriers, and ICI, the situation is far worse.

  13.5 Key Convexity Rules (Your Toolkit)

  These rules help you quickly determine convexity without computing Hessians:

      RULE 1: Sum of convex functions is convex
              Σᵢ fᵢ(x) is convex if each fᵢ is convex

      RULE 2: Affine functions are both convex and concave
              f(x) = aᵀx + b is convex AND concave

      RULE 3: ||Ax + b||² is convex in x
              (quadratic with PSD Hessian = 2AᵀA)

      RULE 4: log(x) is concave (for x > 0)
              log₂(1 + x) is concave in x

      RULE 5: Concave function of affine function is concave
              f(Ax + b) is concave if f is concave

      RULE 6: Ratio f(x)/g(x) is generally NEITHER convex NOR concave
              even if f and g are individually convex

      RULE 7: f(g(x)) — composition:
              convex & non-decreasing ∘ convex → convex
              concave & non-decreasing ∘ concave → concave
              Other combinations → generally non-convex

      RULE 8: Pointwise maximum of convex functions is convex
              max{f₁(x), f₂(x)} is convex if both fᵢ are convex

      RULE 9: Pointwise minimum of concave functions is concave
              min{f₁(x), f₂(x)} is concave if both fᵢ are concave

  Applying to our problem:

  - |H_q[k] · W · F_q[k]|² → This is ||·||² of a bilinear function in (W, F).
  Bilinear is NOT affine in the joint variable (W, F). By Rule 3, ||Ax||² is
  convex in x for fixed A, but if both A and x change, convexity is lost.
  - log₂(1 + SINR) → By Rule 4, log₂(1+x) is concave in x. But SINR is a ratio
  (Rule 6 applies), so the composition is non-convex by Rule 7.
  - The sum Σ Σ log₂(1 + SINR_{q,k}) → By Rule 1, sum of concave functions is
  concave. But each term is neither convex nor concave, so the sum is also
  neither.

  ---
  Part 14: Solution Methods for Non-Convex Wireless Problems

  Since our problem is non-convex, we cannot use standard convex solvers. The
  wireless communications community has developed several strategies. Let me
  explain each one.

  14.1 Method 1: Alternating Optimization (AO)

  The idea: If the joint problem in (W, F) is hard, fix one variable and 
  optimize the other. Then switch.

      ┌─────────────────────────────────────────────────────┐
      │                                                     │
      │  Initialize W⁰ randomly                            │
      │                                                     │
      │  Repeat until convergence:                          │
      │                                                     │
      │    Step A: Fix W^t, solve for F^(t+1):              │
      │            F^(t+1) = argmax_F  SE(W^t, F)           │
      │            (This is often convex or has closed form!)│
      │                                                     │
      │    Step B: Fix F^(t+1), solve for W^(t+1):          │
      │            W^(t+1) = argmax_W  SE(W, F^(t+1))       │
      │            s.t. |W_{m,n}| = 1/√N_t                  │
      │            (Non-convex but lower-dimensional)        │
      │                                                     │
      │  End Repeat                                         │
      │                                                     │
      └─────────────────────────────────────────────────────┘

  Why it works:

  Each sub-problem is easier than the joint problem:
  - Step A (F optimization): With W fixed, the effective channel H_e = H·W is
  known. The problem becomes a standard multi-user MIMO precoding problem,
  solvable by ZF, MMSE, or WMMSE.
  - Step B (W optimization): With F fixed, the problem has only the phase
  variables to optimize, on the manifold.

  Convergence guarantee:

  Let J(W, F) be the objective. At each iteration:
      J(W^t, F^t) ≤ J(W^t, F^(t+1)) ≤ J(W^(t+1), F^(t+1))

  Each step improves or maintains the objective. Since J is bounded above
  (finite power means finite rate), the sequence {J^t} is monotonically
  non-decreasing and bounded, hence convergent by the Monotone Convergence
  Theorem.

  Limitation: Converges to a stationary point (local optimum), not necessarily
  the global optimum.

  This is exactly what the paper uses (Algorithm 2).

  14.2 Method 2: Successive Convex Approximation (SCA)

  The idea: At each iteration, replace the non-convex problem with a convex
  approximation, solve the convex problem, and repeat.

  Mathematical framework:

  At iteration t, with current point x^t, replace the non-convex objective f(x)
  with a convex surrogate f̃(x; x^t) such that:

      (i)    f̃(x^t; x^t) = f(x^t)           (match at current point)
      (ii)   ∇f̃(x^t; x^t) = ∇f(x^t)        (match gradient at current point)
      (iii)  f̃(x; x^t) ≤ f(x)  for all x    (global lower bound — for
  maximization)

  Then solve:
      x^(t+1) = argmax_x  f(x; x^t)    s.t.  constraints

  Common surrogates for wireless problems:

  For log₂(1 + SINR), a popular surrogate comes from the first-order Taylor
  expansion:

      log₂(1 + SINR(x)) ≥ log₂(1 + SINR(x^t)) + [SINR(x) - SINR(x^t)] / [(1 +
  SINR(x^t)) · ln 2]

  This is a linear (hence concave) lower bound on the concave function
  log₂(1+·), evaluated at the point SINR(x^t).

  When to use SCA:
  - When the non-convexity is "mild" (the function is close to convex)
  - When good initial points are available
  - When convex sub-problems can be solved efficiently

  14.3 Method 3: Semidefinite Relaxation (SDR)

  The idea: Lift the problem to a higher-dimensional space where it becomes
  convex (or nearly so).

  The key trick: Replace the rank-1 matrix wwᴴ with a general PSD matrix X:

      Original:    max  wᴴAw / (wᴴBw + σ²)     s.t. |w_i| = 1/√N

      Reformulate: max  Tr(AX) / (Tr(BX) + σ²)  s.t. X ≽ 0, X_{ii} = 1/N,
  rank(X) = 1

      Relax:       max  Tr(AX) / (Tr(BX) + σ²)  s.t. X ≽ 0, X_{ii} = 1/N
                   (drop the rank-1 constraint)

  The relaxed problem is a semidefinite program (SDP), which is convex and
  solvable in polynomial time.

  After solving: If X* has rank 1, we found the exact solution (X* = wwᴴ). If
  rank > 1, use Gaussian randomization to extract an approximate rank-1
  solution.

  When to use SDR:
  - When the problem involves quadratic forms in the optimization variable
  - When the dimension is not too large (SDP solvers scale as O(n³·⁵))
  - Not practical for the paper's problem due to the huge dimensions (N_t × N_RF
   can be 256 × 16)

  14.4 Method 4: Riemannian Manifold Optimization (The Paper's Choice for W)

  The idea: Instead of fighting the constant modulus constraint, embrace it. 
  Work directly on the constraint surface (manifold).

  Standard (Euclidean) gradient descent:
      x^(t+1) = x^t - α · ∇f(x^t)
  Problem: x^(t+1) may violate |x_i| = 1/√N_t.

  Riemannian gradient descent:
      Step 1: Compute Euclidean gradient    g_E = ∇f(x^t)
      Step 2: Project onto tangent space    g_R = Proj_{T_x M}(g_E)
      Step 3: Take step in tangent space    x̃ = x^t - α · g_R
      Step 4: Retract back onto manifold    x^(t+1) = R(x̃)

  Let me explain each step geometrically:

      Manifold M (circle in 2D for illustration)

                g_E (Euclidean gradient,
                ↗    points AWAY from manifold)
               /
      ──── · x^t ───── M
               \
                ↘ g_R (Riemannian gradient,
                       tangent to manifold)
                    \
                     · x̃ (off manifold slightly)
                     |
                     ↓ retraction
                     · x^(t+1) (back on manifold)

  The tangent space projection (for product-of-circles manifold):

  For each component i, the tangent direction must be perpendicular to x_i:

      [g_R]_i = g_{E,i} - Re(g_{E,i} · x_i*) / |x_i|² · x_i

  This removes the component of the gradient that would change the magnitude
  (radial direction), keeping only the component that changes the phase
  (tangential direction).

  The retraction (for product-of-circles manifold):

      [R(x̃)]_i = (1/√N_t) · x̃_i / |x̃_i|

  This normalizes each component back to magnitude 1/√N_t while preserving the 
  phase.

  Why conjugate gradient instead of steepest descent?

  Steepest descent on manifolds suffers from the same problem as in Euclidean
  space — zig-zagging near the optimum:

      Steepest Descent path:          Conjugate Gradient path:

      · → · → · → · → · → ·          · ──────────→ · ────→ ·
      ↓   ↑   ↓   ↑   ↓   ↓          ↓                     ↓
      · → · → · → · → · → ·          · ────────────────→   ·
           (many zig-zags)                  (much fewer steps)

  The Polak-Ribiere conjugate gradient formula (adapted for manifolds):

      β^(t+1) = <g^(t+1), g^(t+1) - T_{x^(t+1)}(g^t)> / ||T_{x^(t+1)}(g^t)||²

      d^(t+1) = g^(t+1) + β^(t+1) · T_{x^(t+1)}(d^t)

  where T_{x^(t+1)}(·) is the vector transport — it moves a tangent vector from
  the tangent space at x^t to the tangent space at x^(t+1). This is necessary
  because tangent spaces at different points on a curved manifold are different
  linear spaces.

  14.5 Method 5: WMMSE (Weighted Minimum Mean Squared Error)

  This is a very important method you should know for your PhD. It is not used
  in this paper but is extremely popular.

  The key insight (Shi et al., 2011): The sum-rate maximization problem:

      max_{W,F}  Σ_q log₂(1 + SINR_q)

  is equivalent to the weighted MSE minimization problem:

      min_{W,F,u,w}  Σ_q [w_q · e_q - log₂(w_q)]

  where:
  - u_q is the receive filter for user q
  - w_q is the MSE weight for user q
  - e_q = E[|s_q - u_q · y_q|²] is the MSE

  Why this helps: The reformulated problem is convex in each variable (u, w, F) 
  when the others are fixed. This enables efficient alternating optimization
  with three blocks instead of two.

  14.6 Comparison Table

  ┌─────────────────────┬──────────────┬──────────────┬──────────────────────┐
  │ Method              │ Guarantee    │ Complexity   │ Best For             │
  ├─────────────────────┼──────────────┼──────────────┼──────────────────────┤
  │ Alternating Opt.    │ Local opt.   │ Medium       │ Separable variables  │
  │ SCA                 │ Stationary   │ Medium       │ Mildly non-convex    │
  │ SDR                 │ Approx.      │ High O(n³·⁵)│ Quadratic problems   │
  │ Manifold Opt.       │ Local opt.   │ Low-Medium   │ Manifold constraints │
  │ WMMSE               │ Stationary   │ Medium       │ Sum-rate problems    │
  │ Branch & Bound      │ Global opt.  │ Exponential  │ Small problems only  │
  │ Deep Learning       │ No guarantee │ Low (online) │ Real-time, large     │
  └─────────────────────┴──────────────┴──────────────┴──────────────────────┘

  ---
  Part 15: The Paper's Reformulation — From Rate Maximization to Interference
  Minimization

  15.1 Why Reformulate?

  The original problem is:

      max_{W,F}  Σ_{q=1}^{U}  Σ_{k=1}^{K}  log₂(1 + SINR_{q,k})       ... (P1)

  The paper replaces it with:

      min_{W}  Σ_{q=1}^{U}  Σ_{k=1}^{K}  I_{q,k}                        ... (P2)

  This is NOT an equivalence — it is an approximation. Let me derive exactly
  when and why this approximation is valid.

  15.2 The Mathematical Justification

  Starting point: For high SINR, we can approximate:

      log₂(1 + SINR) = log₂(SINR + 1)
                     ≈ log₂(SINR)                   when SINR >> 1
                     = log₂(Signal) - log₂(Interference + Noise)

  Therefore:

      max  Σ Σ log₂(1 + SINR_{q,k})

      ≈ max  Σ Σ [log₂(|S₀|²|H_q[k]WF_q[k]|²) - log₂(I_{q,k} + ψ)]

      = max  Σ Σ log₂(Signal_{q,k}) - Σ Σ log₂(I_{q,k} + ψ)

  Now consider the two terms separately:

  Term 1: Σ Σ log₂(Signal_{q,k}) — maximized by aligning beams with channels.
  The ZF digital precoder approximately handles this.

  Term 2: -Σ Σ log₂(I_{q,k} + ψ) — maximized by minimizing interference. Since
  log is monotonically increasing:

      Minimizing  Σ Σ log₂(I_{q,k} + ψ)

      is approximately equivalent to minimizing  Σ Σ I_{q,k}

      when I_{q,k} values are in a similar range (log is nearly linear over
  small ranges)

  Formally, using Jensen's inequality and the concavity of log:

      Σ Σ log₂(I_{q,k} + ψ) ≤ U·K · log₂( (1/UK) Σ Σ (I_{q,k} + ψ) )
                             = U·K · log₂( (1/UK) Σ Σ I_{q,k}  +  ψ )

  Minimizing the right side (which involves the average interference) is
  achieved by minimizing Σ Σ I_{q,k}. So minimizing total interference
  approximately minimizes the upper bound on the log-interference sum.

  15.3 The Gradient Complexity Argument

  Beyond the approximation quality, there is a computational reason for the
  reformulation.

  Gradient of the original objective (with respect to one element of W):

      ∂SE/∂W_{m,n} = Σ_q Σ_k  (1/ln2) · 1/(1 + SINR_{q,k}) ·
  ∂SINR_{q,k}/∂W_{m,n}

  The SINR derivative requires the quotient rule:

      ∂SINR/∂W = [∂(Numerator)/∂W · Denominator - Numerator · ∂(Denominator)/∂W]

  ─────────────────────────────────────────────────────────────────
                                          Denominator²

  Each of these partial derivatives involves matrix products with H, W, F for
  all users and all subcarriers (because W appears everywhere). The total cost
  per gradient evaluation:

      Original:  O(U² · K² · N_t · N_RF)   (due to the ratio and log)

  Gradient of the reformulated objective:

      ∂(Σ I_{q,k})/∂W_{m,n} = Σ_q Σ_k  ∂I_{q,k}/∂W_{m,n}

  Since I_{q,k} = Σ |S_{i-k}|² · |H_q[i] · W · F_u[i]|², the gradient is:

      ∂|H_q[i] · W · F_u[i]|²/∂W = ∂(F_u[i]ᴴ · Wᴴ · H_q[i]ᴴ · H_q[i] · W ·
  F_u[i])/∂W
                                   = 2 · H_q[i]ᴴ · H_q[i] · W · F_u[i] · F_u[i]ᴴ

  This is a quadratic form in W — no division, no logarithm. The gradient is
  simply a matrix product:

      Reformulated:  O(U · K · N_t · N_RF)   (linear, not quadratic)

  Speedup factor: roughly U · K, which can be very significant. The paper
  reports 13× speedup (Table II: 986.9s vs 74.0s).

  15.4 When Does This Approximation Fail?

  The approximation works well when:
      ✓ High SNR regime (SINR >> 1, so log₂(1+SINR) ≈ log₂(SINR))
      ✓ Interference-limited regime (I >> ψ, so noise is negligible)
      ✓ Massive MIMO regime (many antennas provide high beamforming gain)

  The approximation degrades when:
      ✗ Low SNR regime (SINR ≈ 0, log₂(1+SINR) ≈ SINR/ln2, linear not log)
      ✗ Noise-limited regime (I << ψ, interference doesn't matter)
      ✗ Few antennas (beamforming gain is small)

  The paper's Figure 2 shows the gap between the original and reformulated
  problems — it is small across the SNR range considered (0-30 dB), confirming
  the approximation is good for the THz massive MIMO scenario.

  ---
  Part 16: The Complete Solution Pipeline — Tying Everything Together

  Let me now show how all the pieces fit together in a complete algorithm flow:

      ┌─────────────────────────────────────────────────────────────┐
      │                    ALGORITHM 2 (Full Pipeline)               │
      │                                                             │
      │  INPUT: Channel matrices H_q[k] for all q, k               │
      │         ICI coefficients S_{i-k}                            │
      │         System parameters: N_t, N_RF, U, K, P, σ²          │
      │                                                             │
      │  INITIALIZE:                                                │
      │    W⁰: random phases, |W_{m,n}| = 1/√N_t                   │
      │    t = 0                                                    │
      │                                                             │
      │  REPEAT:                                                    │
      │  ┌─────────────────────────────────────────────────────┐    │
      │  │  STEP 1: Digital Precoder Design (Fix W^t)          │    │
      │  │                                                     │    │
      │  │  For each subcarrier k = 1, ..., K:                 │    │
      │  │    (a) Compute effective channel:                    │    │
      │  │        H_e[k] = H[k] · W^t                         │    │
      │  │                                                     │    │
      │  │    (b) Compute ZF precoder:                         │    │
      │  │        F[k] = H_e[k]ᴴ · (H_e[k] · H_e[k]ᴴ)⁻¹     │    │
      │  │                                                     │    │
      │  │    (c) Normalize:                                   │    │
      │  │        For each user u:                             │    │
      │  │        F_u[k] = F_u[k] / ||W^t · F_u[k]||          │    │
      │  │                                                     │    │
      │  │  Complexity: O(K · N_RF² · U)  per iteration        │    │
      │  └─────────────────────────────────────────────────────┘    │
      │                          ↓                                  │
      │  ┌─────────────────────────────────────────────────────┐    │
      │  │  STEP 2: Analog Precoder Design (Fix F^(t+1))       │    │
      │  │                                                     │    │
      │  │  Solve: min_W  Σ_q Σ_k I_{q,k}(W, F^(t+1))        │    │
      │  │  s.t.   |W_{m,n}| = 1/√N_t                         │    │
      │  │                                                     │    │
      │  │  Using Algorithm 1 (Riemannian Conjugate Gradient): │    │
      │  │    (a) Compute Euclidean gradient of Σ I_{q,k}      │    │
      │  │    (b) Project onto tangent space of manifold       │    │
      │  │    (c) Conjugate gradient update                    │    │
      │  │    (d) Retract onto manifold                        │    │
      │  │    (e) Repeat until inner convergence               │    │
      │  │                                                     │    │
      │  │  Complexity: O(T_inner · U · K · N_t · N_RF)        │    │
      │  └─────────────────────────────────────────────────────┘    │
      │                          ↓                                  │
      │  ┌─────────────────────────────────────────────────────┐    │
      │  │  STEP 3: Convergence Check                          │    │
      │  │                                                     │    │
      │  │  Compute: R_sum = Σ_q Σ_k I_{q,k}(W^(t+1), F^(t+1))│    │
      │  │                                                     │    │
      │  │  If |R_sum^(t+1) - R_sum^t| / |R_sum^t| < ε:        │    │
      │  │     STOP (converged)                                │    │
      │  │  Else:                                              │    │
      │  │     t = t + 1, go to STEP 1                         │    │
      │  └─────────────────────────────────────────────────────┘    │
      │                                                             │
      │  OUTPUT: W*, F*[k] for all k                                │
      └─────────────────────────────────────────────────────────────┘

  16.1 Convergence Analysis

  Theorem (Convergence of Algorithm 2):

  The sequence {R_sum^t}_{t=0}^∞ generated by Algorithm 2 is monotonically
  non-increasing and bounded below, hence convergent.

  Proof:

  (i) Monotonicity: At each outer iteration:
  - Step 1 computes the optimal F for fixed W^t. Since ZF with power
  normalization is the solution to the per-subcarrier multi-user precoding
  problem, we have:

      R_sum(W^t, F^(t+1)) ≤ R_sum(W^t, F^t)

  (Note: for the original problem this would be ≥ for SE. For the reformulated
  problem where we minimize interference, we get ≤ for R_sum.)

  Actually, let me be more precise. The ZF precoder eliminates inter-user
  interference on each subcarrier. When W changes, F must be recomputed. The key
   insight is:

  - Step 1: Given W^t, compute the best F. This gives R_sum(W^t, F^(t+1)).
  - Step 2: Given F^(t+1), find a better W. Since Algorithm 1 uses gradient 
  descent on the manifold: R_sum(W^(t+1), F^(t+1)) ≤ R_sum(W^t, F^(t+1)).

  Combining: R_sum(W^(t+1), F^(t+1)) ≤ R_sum(W^t, F^(t+1)) ≤ R_sum(W^t, F^t)

  Wait — the inequality directions depend on whether F^(t+1) reduces R_sum
  compared to F^t. Since ZF may not minimize total interference directly, the
  precise guarantee is:

      R_sum^(t+1) = R_sum(W^(t+1), F^(t+1))  ≤  R_sum(W^t, F^(t+1))  (Step 2
  improves W)

  Step 2 alone guarantees descent.

  (ii) Boundedness: R_sum = Σ I_{q,k} ≥ 0 (sum of squared magnitudes is
  non-negative).

  (iii) Convergence: A monotonically non-increasing sequence bounded below
  converges (by the Monotone Convergence Theorem).

  Rate of convergence: The conjugate gradient method on the manifold typically
  converges superlinearly for quadratic-like cost functions, meaning the number
  of inner iterations is small (often O(√N) where N is the problem dimension).

  ---
  Part 17: Connection to Modern Research Directions

  17.1 How This Problem Evolves in Current Research (2023-2026)

  The optimization problem in this paper is a foundation. Modern research builds
   on it in several directions:

  Direction 1: Deep Learning-Based Beamforming

  Instead of solving the optimization iteratively, train a neural network:

      Input: H (channel) → Neural Network → Output: W, F (beamforming matrices)

  The optimization problem becomes the loss function for training:

      min_θ  E_H[ -SE(W_θ(H), F_θ(H)) ]     (θ = neural network parameters)

  Advantages: Near-instant inference (microseconds vs. milliseconds)
  Disadvantages: Requires training data, may not generalize

  Direction 2: RIS-Assisted Systems

  Reconfigurable Intelligent Surfaces add a new optimization variable Φ (the RIS
   phase shift matrix):

      max_{W, F, Φ}  Σ Σ log₂(1 + SINR_{q,k})
      s.t.  |W_{m,n}| = 1/√N_t
            |Φ_{l,l}| = 1              ← NEW: RIS elements are also phase-only
            ||W·F_u[k]||² = 1

  The RIS constraint is another constant-modulus constraint! The problem has two
   manifold constraints now, requiring more sophisticated alternating
  optimization.

  Direction 3: Wideband THz with Beam Squint

  At THz with very large bandwidth, the beam direction changes across
  subcarriers (beam squint). This adds a physics constraint:

      W(f_k) = W₀ · diag(e^(j2π(f_k-f_c)τ₁), ..., e^(j2π(f_k-f_c)τ_{N_t}))

  The analog precoder becomes frequency-dependent through the delay structure,
  creating a true-time-delay constraint.

  Direction 4: Multi-Objective Optimization

  Instead of maximizing SE alone, optimize multiple objectives:

      max  {SE,  Energy_Efficiency,  Fairness}     (Pareto optimization)

  This requires finding the Pareto frontier — the set of solutions where no
  objective can be improved without worsening another.

  17.2 The Big Picture: Where Your Problem Fits

      ┌────────────────────────────────────────────────────────────────┐
      │                TAXONOMY OF WIRELESS OPTIMIZATION               │
      │                                                                │
      │  By Variable:                                                  │
      │    • Beamforming/precoding (this paper)                        │
      │    • Power allocation                                          │
      │    • Subcarrier/resource assignment                            │
      │    • User scheduling                                           │
      │    • Joint design (multiple of the above)                      │
      │                                                                │
      │  By Objective:                                                 │
      │    • Sum-rate maximization (this paper)                        │
      │    • Max-min fairness                                          │
      │    • Energy efficiency                                         │
      │    • MSE minimization                                          │
      │    • Outage probability minimization                           │
      │                                                                │
      │  By Constraint Type:                                           │
      │    • Convex constraints only → easier                          │
      │    • Manifold constraints (this paper) → moderate              │
      │    • Discrete/integer constraints → hardest                    │
      │                                                                │
      │  By Solution Method:                                           │
      │    • Closed-form (ZF, MMSE) → fastest                          │
      │    • Convex optimization (CVX, SDP) → guaranteed               │
      │    • Iterative (AO, SCA, WMMSE) → practical                   │
      │    • Manifold optimization (this paper) → elegant              │
      │    • Deep learning → emerging                                  │
      └────────────────────────────────────────────────────────────────┘

  ---
  Summary of Chunk 3
  Topic: Convexity
  Key Takeaway: Hessian must be PSD everywhere; our problem's Hessian is
    indefinite
  ────────────────────────────────────────
  Topic: Convexity rules
  Key Takeaway: Ratio of functions → non-convex; log of non-convex → non-convex;

    bilinear coupling → non-convex
  ────────────────────────────────────────
  Topic: Alternating optimization
  Key Takeaway: Fix one variable, optimize other; guaranteed convergence to
  local
     optimum
  ────────────────────────────────────────
  Topic: SCA
  Key Takeaway: Replace non-convex with convex approximation at each step
  ────────────────────────────────────────
  Topic: SDR
  Key Takeaway: Lift to higher dimension, relax rank constraint; good but
    expensive
  ────────────────────────────────────────
  Topic: Manifold optimization
  Key Takeaway: Work directly on constraint surface; elegant for
  constant-modulus
  ────────────────────────────────────────
  Topic: WMMSE
  Key Takeaway: Transform rate-max to weighted-MSE-min; powerful but not used in

    this paper
  ────────────────────────────────────────
  Topic: Reformulation justification
  Key Takeaway: At high SINR: max rate ≈ min interference; gradient is O(UK)
    cheaper
  ────────────────────────────────────────
  Topic: When approximation fails
  Key Takeaway: Low SNR, noise-limited regime, few antennas
  ────────────────────────────────────────
  Topic: Convergence proof
  Key Takeaway: Monotone decreasing + bounded below → convergent (Monotone
    Convergence Theorem)
  ────────────────────────────────────────
  Topic: Modern directions
  Key Takeaway: Deep learning, RIS, beam squint, multi-objective Pareto
    optimization
  ---
  In Chunk 4 (Final), I will cover:
  1. A complete worked numerical example — plugging in actual numbers (N_t=64,
  N_RF=4, U=4, K=128) and showing what happens at each step
  2. How to write the problem formulation section of your own paper — with a
  template
  3. Common mistakes PhD students make in optimization formulation and how to
  avoid them
  4. Reading list — the essential papers to build your PhD foundation

  Reply "next" when you are ready for Chunk 4.

✻ Brewed for 3m 21s